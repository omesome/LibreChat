# For more information, see the Configuration Guide:
# https://www.librechat.ai/docs/configuration/librechat_yaml

# Configuration version (required)
version: 1.2.1

# Cache settings: Set to true to enable caching
cache: true

# Custom interface configuration
interface:
  customWelcome: "Hey {{user.name}}, welcome to Jolt. What's Up?"
  fileSearch: false
  endpointsMenu: false
  modelSelect: false
  parameters: false
  sidePanel: false
  presets: false
  prompts:
    use: true
    share: false
    public: false
  bookmarks: false
  multiConvo: false
  agents:
    use: true
    share: false
    public: false
  fileCitations: true

modelSpecs:
  enforce: true
  prioritize: true
  list:
    - name: "claude-haiku"
      label: "Jolt Haiku ‚ö°Ô∏è"
      description: "fast and efficient"
      default: true
      preset:
        endpoint: "anthropic"
        model: "claude-haiku-4-5-20251001"
        maxContextTokens: 128000 # Maximum context tokens
        max_tokens: 4096 # Maximum output tokens
        modelLabel: "Jolty"
        promptCache: true
        thinking: false
        greeting: Time to procrasti-nope ‚ö°Ô∏è
        promptPrefix: &prefix |
          You are supposed to keep me from procrastinating. 
          Give specific suggestions to do to improve my mood or get productive.
          Do not suggest I write things down, think of things on my own or make lists. 
          Do not allow me to do unproductive things. 
          Do not provide me with multiple options or make me choose. 
          Just concrete suggestions or commands of what to do.
          When you give commands ask "sound like a plan?" or something like that.
          If I say i‚Äôll do it, wait for me to check in after i‚Äôve done it, then congratulate me and ask me how I feel, before offering more help.
          You can ask me about a goal i want to work on and push me to do it in small steps, without accepting no or wanting to do other things.
          Only ever suggest one action at a time.
    - name: "claude-sonnet"
      label: "Jolt Sonnet üí°"
      description: "Smart and talkative"
      preset:
        endpoint: "anthropic"
        model: "claude-sonnet-4-5-20250929"
        maxContextTokens: 128000 # Maximum context tokens
        max_tokens: 4096 # Maximum output tokens
        modelLabel: "Jolt"
        promptCache: true
        thinking: false
        greeting: Time to procrasti-nope üí°
        promptPrefix: *prefix
    - name: "chat-gpt"
      label: &gpt "JoltGPT üß†"
      description: "Smart and talkative"
      preset:
        endpoint: "openAI"
        model: "gpt-5.2"
        maxContextTokens: 128000 # Maximum context tokens
        max_tokens: 4096 # Maximum output tokens
        modelLabel: *gpt
        promptCache: true
        thinking: false
        greeting: Time to procrasti-nope üí°
        promptPrefix: *prefix
    - name: "chat-gpt-mini"
      label: "JoltGPT mini üèéÔ∏è"
      description: "Smart and talkative"
      preset:
        endpoint: "openAI"
        model: "gpt-5-mini"
        maxContextTokens: 128000 # Maximum context tokens
        max_tokens: 4096 # Maximum output tokens
        promptCache: true
        thinking: false
        greeting: Time to procrasti-nope ‚ö°Ô∏è
        promptPrefix: *prefix
   

# Memory configuration for user memories
# memory:
#   # (optional) Disable memory functionality
#   disabled: false
#   # (optional) Restrict memory keys to specific values to limit memory storage and improve consistency
#   validKeys: ["preferences", "work_info", "personal_info", "skills", "interests", "context"]
#   # (optional) Maximum token limit for memory storage (not yet implemented for token counting)
#   tokenLimit: 10000
#   # (optional) Enable personalization features (defaults to true if memory is configured)
#   # When false, users will not see the Personalization tab in settings
#   personalize: true
#   # Memory agent configuration - either use an existing agent by ID or define inline
#   agent:
#     # Option 1: Use existing agent by ID
#     id: "your-memory-agent-id"
#     # Option 2: Define agent inline
#     # provider: "openai"
#     # model: "gpt-4o-mini"
#     # instructions: "You are a memory management assistant. Store and manage user information accurately."
#     # model_parameters:
#     #   temperature: 0.1
